
Du:
# Funktion: Procrustes-Analyse
def procrustes_analysis(A, B):
    A_centroid, B_centroid = np.mean(A, axis=0), np.mean(B, axis=0)
    A_centered, B_centered = A - A_centroid, B - B_centroid
    A_scale = np.sqrt(np.sum(A_centered**2) / A_centered.shape[0])
    B_scale = np.sqrt(np.sum(B_centered**2) / B_centered.shape[0])
    A_normalized, B_normalized = A_centered / A_scale, B_centered / B_scale

    H = B_normalized.T @ A_normalized
    U, _, Vt = np.linalg.svd(H)
    R = Vt.T @ U.T
    A_transformed = A_normalized @ R

    marker_errors_in_mm = np.linalg.norm((A_transformed - B_normalized), axis=1) * B_scale
    mpjpe_in_mm = np.mean(marker_errors_in_mm)
    return mpjpe_in_mm, marker_errors_in_mm
ChatGPT:
Your function procrustes_analysis looks good overall, but I noticed a few things to improve or clarify for better readability and efficiency:

Input Assumptions: It seems like A and B are point sets or coordinate matrices (each with rows as points and columns as coordinates). It would be helpful to clarify this in the function description or documentation.

Scaling Consistency: The scaling factors A_scale and B_scale are calculated as the average distance of points from the centroid (which is good for Procrustes analysis). However, the calculation might not be fully general if A and B have different dimensions. For consistency, you could explicitly ensure that both point sets are 2D.

Matrix Multiplications: You are using matrix operations and SVD correctly for computing the rotation matrix R. Just a small recommendation: you might want to check for numerical stability or possible reflection issues in R, but in most cases, this should be fine.

Here is an improved and slightly commented version of your code:

python
Kopieren
import numpy as np

def procrustes_analysis(A, B):
    # Compute centroids of A and B
    A_centroid, B_centroid = np.mean(A, axis=0), np.mean(B, axis=0)
    
    # Center the data (subtract the centroid)
    A_centered, B_centered = A - A_centroid, B - B_centroid
    
    # Compute scale factors (RMS of distances from the centroid)
    A_scale = np.sqrt(np.sum(A_centered**2) / A_centered.shape[0])
    B_scale = np.sqrt(np.sum(B_centered**2) / B_centered.shape[0])
    
    # Normalize the data by the scale
    A_normalized, B_normalized = A_centered / A_scale, B_centered / B_scale

    # Compute the matrix H for the Procrustes alignment
    H = B_normalized.T @ A_normalized
    
    # Perform Singular Value Decomposition (SVD)
    U, _, Vt = np.linalg.svd(H)
    
    # Compute the rotation matrix R
    R = Vt.T @ U.T
    
    # Apply the rotation to A
    A_transformed = A_normalized @ R
    
    # Calculate the marker errors (distance between transformed A and B)
    marker_errors_in_mm = np.linalg.norm((A_transformed - B_normalized), axis=1) * B_scale
    
    # Compute Mean Per Joint Position Error (MPJPE)
    mpjpe_in_mm = np.mean(marker_errors_in_mm)
    
    return mpjpe_in_mm, marker_errors_in_mm
Key Points:
Centroid Calculation: The centroid is correctly computed as the mean of all points.
Centering: The data is centered by subtracting the centroid, ensuring the comparison is based on relative positions.
Scaling: Scaling factors are computed as the root-mean-square (RMS) of the distances from the centroid, normalizing both point sets.
Rotation Matrix: SVD is used to find the optimal rotation matrix R between the point sets.
Transformation and Error: A is transformed by the rotation matrix, and the error (MPJPE) is calculated based on the transformed data.
This should work well if the point sets A and B are of the same dimensionality (e.g., 2D or 3D). Let me know if you need any further improvements or clarifications!






Du:
ich möchte vor markers_error_in_mm noch den vektor von A_transformed zu B_normalized berechnen und als return herausgeben
ChatGPT:
Natürlich! Um den Vektor zwischen A_transformed und B_normalized zu berechnen, kannst du den Unterschied zwischen diesen beiden Matrizen direkt berechnen. Dieser Vektor repräsentiert den Unterschied (Verschiebung) zwischen den transformierten Punkten von A und den normalisierten Punkten von B. Wir können diesen Vektor als zusätzliche Ausgabe vor den marker_errors_in_mm hinzufügen.

Hier ist der angepasste Code, der den Vektor von A_transformed zu B_normalized berechnet und als zusätzliche Rückgabe liefert:

python
Kopieren
import numpy as np

def procrustes_analysis(A, B):
    # Compute centroids of A and B
    A_centroid, B_centroid = np.mean(A, axis=0), np.mean(B, axis=0)
    
    # Center the data (subtract the centroid)
    A_centered, B_centered = A - A_centroid, B - B_centroid
    
    # Compute scale factors (RMS of distances from the centroid)
    A_scale = np.sqrt(np.sum(A_centered**2) / A_centered.shape[0])
    B_scale = np.sqrt(np.sum(B_centered**2) / B_centered.shape[0])
    
    # Normalize the data by the scale
    A_normalized, B_normalized = A_centered / A_scale, B_centered / B_scale

    # Compute the matrix H for the Procrustes alignment
    H = B_normalized.T @ A_normalized
    
    # Perform Singular Value Decomposition (SVD)
    U, _, Vt = np.linalg.svd(H)
    
    # Compute the rotation matrix R
    R = Vt.T @ U.T
    
    # Apply the rotation to A
    A_transformed = A_normalized @ R
    
    # Calculate the vector from A_transformed to B_normalized (difference)
    difference_vector = A_transformed - B_normalized
    
    # Calculate the marker errors (distance between transformed A and B)
    marker_errors_in_mm = np.linalg.norm(difference_vector, axis=1) * B_scale
    
    # Compute Mean Per Joint Position Error (MPJPE)
    mpjpe_in_mm = np.mean(marker_errors_in_mm)
    
    return mpjpe_in_mm, marker_errors_in_mm, difference_vector
Änderungen:
difference_vector: Dieser Vektor wird berechnet, indem A_transformed von B_normalized subtrahiert wird. Das Ergebnis ist ein Vektor, der die Verschiebung für jeden Punkt darstellt.
Rückgabe: Die Funktion gibt jetzt auch den difference_vector zusammen mit den anderen Metriken zurück.
Rückgabewerte:
mpjpe_in_mm: Der mittlere Fehler in Millimetern (Mean Per Joint Position Error).
marker_errors_in_mm: Der Fehler für jeden Marker in Millimetern.
difference_vector: Der Vektor, der die Differenz zwischen den transformierten Punkten von A und den normalisierten Punkten von B darstellt.
Lass mich wissen, falls du noch Anpassungen benötigst!






Du:
# Hauptprozess
for person in persons:
    for trial in person_to_trials[person]:
        print(f"Processing {person} - {trial}...")

        # Lade Dateien
        vicon_file, poseformer_file = generate_file_paths(person, trial)
        if not os.path.exists(vicon_file) or not os.path.exists(poseformer_file):
            print(f"File not found: {vicon_file} or {poseformer_file}")
            continue

        vicon_data = pd.read_csv(vicon_file)
        poseformer_data = pd.read_csv(poseformer_file, header=None)
        
        # Entfernen der HIPMIDDLE
        excluded_columns_vicon = [col for col in vicon_data.columns if any(marker in col for marker in ['HIPMIDDLE'])]
        excluded_columns_indices = [vicon_data.columns.get_loc(col) for col in excluded_columns_vicon]
        vicon_data_cleaned = vicon_data.drop(columns=excluded_columns_vicon)
        poseformer_data_cleaned = poseformer_data.drop(columns=poseformer_data.columns[excluded_columns_indices])
       
    
        
        # Extrahieren der Marker-Namen
        marker_names = [col.split(':')[0] for col in vicon_data_cleaned.columns if ':X' in col]
        num_frames = min(len(vicon_data_cleaned), len(poseformer_data_cleaned))
 
        results = []
        for i in range(start_frame, min(end_frame + 1, num_frames + 1)):
            vicon_frame = vicon_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            poseformer_frame = poseformer_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            if not (np.isnan(vicon_frame).any() or np.isnan(poseformer_frame).any()):
                try:
                    mpjpe, marker_errors = procrustes_analysis(poseformer_frame, vicon_frame)
                    results.append([i, mpjpe] + marker_errors.tolist())
                except np.linalg.LinAlgError:
                    results.append([i, np.nan] + [np.nan] * len(marker_names))
            else:
                results.append([i, np.nan] + [np.nan] * len(marker_names))

        # Ergebnisse speichern
        columns = ['Frame', 'MPJPE (mm)'] + [f'{marker} Error (mm)' for marker in marker_names]
        result_df = pd.DataFrame(results, columns=columns)

        # Speichern der Ergebnisse
        output_file = f'E:/Datenerhebung MA/MPJPE/Poseformer/Cam1/{person}_{trial}_MPJPE_vector.csv'
        result_df.to_csv(output_file, index=False)
        print(f"Results saved to {output_file}.")

wie muss ich dann diesen teil noch anpassen
ChatGPT:
Der Code, den du gepostet hast, scheint bereits gut strukturiert zu sein, um für jede Person und jeden Versuch (trial) die Procrustes-Analyse durchzuführen, die Fehler für jedes Frame zu berechnen und die Ergebnisse in einer CSV-Datei zu speichern.

Da du die Funktion procrustes_analysis bereits so angepasst hast, dass sie jetzt auch den difference_vector zurückgibt, müssen wir den Code an der Stelle anpassen, an der du die Ergebnisse sammelst, damit dieser Vektor ebenfalls gespeichert wird. Der Vektor difference_vector wird als zusätzliche Spalte in das DataFrame eingefügt.

Hier ist die angepasste Version des Codes, in der der difference_vector zusammen mit den Fehlern gespeichert wird:

Angepasster Code:
python
Kopieren
# Hauptprozess
for person in persons:
    for trial in person_to_trials[person]:
        print(f"Processing {person} - {trial}...")

        # Lade Dateien
        vicon_file, poseformer_file = generate_file_paths(person, trial)
        if not os.path.exists(vicon_file) or not os.path.exists(poseformer_file):
            print(f"File not found: {vicon_file} or {poseformer_file}")
            continue

        vicon_data = pd.read_csv(vicon_file)
        poseformer_data = pd.read_csv(poseformer_file, header=None)
        
        # Entfernen der HIPMIDDLE
        excluded_columns_vicon = [col for col in vicon_data.columns if any(marker in col for marker in ['HIPMIDDLE'])]
        excluded_columns_indices = [vicon_data.columns.get_loc(col) for col in excluded_columns_vicon]
        vicon_data_cleaned = vicon_data.drop(columns=excluded_columns_vicon)
        poseformer_data_cleaned = poseformer_data.drop(columns=poseformer_data.columns[excluded_columns_indices])
        
        # Extrahieren der Marker-Namen
        marker_names = [col.split(':')[0] for col in vicon_data_cleaned.columns if ':X' in col]
        num_frames = min(len(vicon_data_cleaned), len(poseformer_data_cleaned))
 
        results = []
        for i in range(start_frame, min(end_frame + 1, num_frames + 1)):
            vicon_frame = vicon_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            poseformer_frame = poseformer_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            if not (np.isnan(vicon_frame).any() or np.isnan(poseformer_frame).any()):
                try:
                    mpjpe, marker_errors, difference_vector = procrustes_analysis(poseformer_frame, vicon_frame)
                    # Die Ergebnisse für das aktuelle Frame
                    results.append([i, mpjpe] + marker_errors.tolist() + difference_vector.flatten().tolist())
                except np.linalg.LinAlgError:
                    # Fehlerfall
                    results.append([i, np.nan] + [np.nan] * len(marker_names) + [np.nan] * 3)  # 3 für den 3D-Vektor
            else:
                # Falls NaN-Werte vorhanden sind
                results.append([i, np.nan] + [np.nan] * len(marker_names) + [np.nan] * 3)  # 3 für den 3D-Vektor

        # Ergebnisse speichern
        columns = ['Frame', 'MPJPE (mm)'] + [f'{marker} Error (mm)' for marker in marker_names] + ['Difference Vector X', 'Difference Vector Y', 'Difference Vector Z']
        result_df = pd.DataFrame(results, columns=columns)

        # Speichern der Ergebnisse
        output_file = f'E:/Datenerhebung MA/MPJPE/Poseformer/Cam1/{person}_{trial}_MPJPE_vector.csv'
        result_df.to_csv(output_file, index=False)
        print(f"Results saved to {output_file}.")
Änderungen im Detail:
Zusätzliche Rückgabe aus procrustes_analysis:

Wir holen nun den difference_vector zusätzlich zu den Fehlern (Marker-Fehlern).
Dieser difference_vector ist der Unterschied zwischen den transformierten poseformer-Daten und den vicon-Daten.
Ergebnisse speichern:

In der results.append()-Zeile wird der difference_vector zum DataFrame hinzugefügt. Da der difference_vector ein Vektor mit 3 Werten (für X, Y und Z) ist, verwenden wir .flatten() (um sicherzustellen, dass der Vektor als flaches Array behandelt wird) und fügen die einzelnen Komponenten des Vektors als separate Spalten in das Ergebnis ein.
Spaltennamen im DataFrame:

Die Spaltennamen wurden um die Differenzvektor-Spalten (Difference Vector X, Difference Vector Y, Difference Vector Z) erweitert, damit sie im Ergebnis-CSV korrekt angezeigt werden.
Rückgabewerte:
Jetzt gibt der Code für jedes Frame neben dem MPJPE und den marker_errors auch die Komponenten des difference_vector aus, um die Verschiebung in den X-, Y- und Z-Richtungen anzuzeigen.
CSV-Datei:
Die gespeicherte CSV-Datei enthält nun für jedes Frame:

Frame: Die Nummer des Frames
MPJPE (mm): Der mittlere Fehler pro Gelenk in Millimetern
Marker Error (mm): Der Fehler jedes Markers in Millimetern
Difference Vector X, Difference Vector Y, Difference Vector Z: Die Komponenten des Vektors, der den Unterschied zwischen den transformierten poseformer-Daten und den vicon-Daten darstellt.
Beispielausgabe in CSV:
scss
Kopieren
Frame, MPJPE (mm), Marker1 Error (mm), Marker2 Error (mm), ..., Difference Vector X, Difference Vector Y, Difference Vector Z
1, 5.2, 0.2, 0.3, ..., 0.01, -0.02, 0.03
2, 4.8, 0.1, 0.4, ..., 0.02, -0.01, 0.05
...
Lass mich wissen, ob noch etwas anderes angepasst werden muss!






Du:
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\internals\construction.py:939, in _finalize_columns_and_data(content, columns, dtype)
    938 try:
--> 939     columns = _validate_or_indexify_columns(contents, columns)
    940 except AssertionError as err:
    941     # GH#26429 do not raise user-facing AssertionError

File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\internals\construction.py:986, in _validate_or_indexify_columns(content, columns)
    984 if not is_mi_list and len(columns) != len(content):  # pragma: no cover
    985     # caller's responsibility to check for this...
--> 986     raise AssertionError(
    987         f"{len(columns)} columns passed, passed data had "
    988         f"{len(content)} columns"
    989     )
    990 if is_mi_list:
    991     # check if nested list column, length of each sub-list should be equal

AssertionError: 17 columns passed, passed data had 50 columns

The above exception was the direct cause of the following exception:

ValueError                                Traceback (most recent call last)
Cell In[3], line 90
     88 # Ergebnisse speichern
     89 columns = ['Frame', 'MPJPE (mm)'] + [f'{marker} Error (mm)' for marker in marker_names] + ['Difference Vector X', 'Difference Vector Y', 'Difference Vector Z']
---> 90 result_df = pd.DataFrame(results, columns=columns)
     92 # Speichern der Ergebnisse
     93 output_file = f'E:/Datenerhebung MA/MPJPE/Poseformer/Cam1/{person}_{trial}_MPJPE_vector.csv'

File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\frame.py:806, in DataFrame.__init__(self, data, index, columns, dtype, copy)
    804     if columns is not None:
    805         columns = ensure_index(columns)
--> 806     arrays, columns, index = nested_data_to_arrays(
    807         # error: Argument 3 to "nested_data_to_arrays" has incompatible
    808         # type "Optional[Collection[Any]]"; expected "Optional[Index]"
    809         data,
    810         columns,
    811         index,  # type: ignore[arg-type]
    812         dtype,
    813     )
    814     mgr = arrays_to_mgr(
    815         arrays,
    816         columns,
   (...)
    819         typ=manager,
    820     )
    821 else:

File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\internals\construction.py:520, in nested_data_to_arrays(data, columns, index, dtype)
    517 if is_named_tuple(data[0]) and columns is None:
    518     columns = ensure_index(data[0]._fields)
--> 520 arrays, columns = to_arrays(data, columns, dtype=dtype)
    521 columns = ensure_index(columns)
    523 if index is None:

File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\internals\construction.py:845, in to_arrays(data, columns, dtype)
    842     data = [tuple(x) for x in data]
    843     arr = _list_to_arrays(data)
--> 845 content, columns = _finalize_columns_and_data(arr, columns, dtype)
    846 return content, columns

File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\internals\construction.py:942, in _finalize_columns_and_data(content, columns, dtype)
    939     columns = _validate_or_indexify_columns(contents, columns)
    940 except AssertionError as err:
    941     # GH#26429 do not raise user-facing AssertionError
--> 942     raise ValueError(err) from err
    944 if len(contents) and contents[0].dtype == np.object_:
    945     contents = convert_object_array(contents, dtype=dtype)

ValueError: 17 columns passed, passed data had 50 columns
ChatGPT:
Der Fehler, den du erhältst, deutet darauf hin, dass die Anzahl der Spalten in den Daten, die du zu erstellen versuchst, nicht mit der Anzahl der Spalten übereinstimmt, die du in columns definiert hast. Genauer gesagt, die Liste columns erwartet 17 Spalten (basierend auf den marker_names und den zusätzlichen Differenzvektor-Spalten), während die results-Daten 50 Spalten enthalten.

Dieser Fehler tritt möglicherweise auf, weil die Länge der Marker-Namen in marker_names nicht mit der Anzahl der Fehler übereinstimmt, die tatsächlich in den results eingefügt werden. Der Fehler tritt wahrscheinlich auf, wenn entweder mehr Marker-Fehler als erwartet berechnet werden oder ein Problem mit den Dimensionen des difference_vector besteht.

Fehlerbehebung:
Überprüfe die Anzahl der Marker und Fehler: Die results-Daten müssen genau so viele Marker-Fehler enthalten wie die Anzahl der Marker in marker_names. Achte darauf, dass der difference_vector für jedes Frame korrekt als 3-Werte-Vektor (X, Y, Z) zu den Fehlerwerten hinzugefügt wird.

Dimensionalität von difference_vector: Der difference_vector ist in der Regel ein 2D-Array (jedes Element ist ein 3D-Vektor). Möglicherweise tritt der Fehler auf, weil du versuchst, den difference_vector als flaches Array hinzuzufügen, aber die Dimensionen stimmen nicht überein. Du kannst sicherstellen, dass der Vektor korrekt in der Ergebnistabelle platziert wird.

Hier ist eine überarbeitete Version des relevanten Teils des Codes, um die Dimensionen richtig zu handhaben und den Fehler zu vermeiden:

Korrigierte Version des Codes:
python
Kopieren
# Hauptprozess
for person in persons:
    for trial in person_to_trials[person]:
        print(f"Processing {person} - {trial}...")

        # Lade Dateien
        vicon_file, poseformer_file = generate_file_paths(person, trial)
        if not os.path.exists(vicon_file) or not os.path.exists(poseformer_file):
            print(f"File not found: {vicon_file} or {poseformer_file}")
            continue

        vicon_data = pd.read_csv(vicon_file)
        poseformer_data = pd.read_csv(poseformer_file, header=None)
        
        # Entfernen der HIPMIDDLE
        excluded_columns_vicon = [col for col in vicon_data.columns if any(marker in col for marker in ['HIPMIDDLE'])]
        excluded_columns_indices = [vicon_data.columns.get_loc(col) for col in excluded_columns_vicon]
        vicon_data_cleaned = vicon_data.drop(columns=excluded_columns_vicon)
        poseformer_data_cleaned = poseformer_data.drop(columns=poseformer_data.columns[excluded_columns_indices])
        
        # Extrahieren der Marker-Namen
        marker_names = [col.split(':')[0] for col in vicon_data_cleaned.columns if ':X' in col]
        num_frames = min(len(vicon_data_cleaned), len(poseformer_data_cleaned))
 
        results = []
        for i in range(start_frame, min(end_frame + 1, num_frames + 1)):
            vicon_frame = vicon_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            poseformer_frame = poseformer_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            if not (np.isnan(vicon_frame).any() or np.isnan(poseformer_frame).any()):
                try:
                    mpjpe, marker_errors, difference_vector = procrustes_analysis(poseformer_frame, vicon_frame)
                    # Wenn difference_vector ein 2D-Array ist (z.B. [Anzahl Marker x 3])
                    # Flatten und mit den Fehlern und MPJPE an die Ergebnisse anhängen
                    difference_vector_flat = difference_vector.flatten()  # Umwandeln in flache Liste
                    results.append([i, mpjpe] + marker_errors.tolist() + difference_vector_flat.tolist())
                except np.linalg.LinAlgError:
                    # Fehlerfall
                    results.append([i, np.nan] + [np.nan] * len(marker_names) + [np.nan] * 3)  # 3 für den 3D-Vektor
            else:
                # Falls NaN-Werte vorhanden sind
                results.append([i, np.nan] + [np.nan] * len(marker_names) + [np.nan] * 3)  # 3 für den 3D-Vektor

        # Ergebnisse speichern
        columns = ['Frame', 'MPJPE (mm)'] + [f'{marker} Error (mm)' for marker in marker_names] + ['Difference Vector X', 'Difference Vector Y', 'Difference Vector Z']
        result_df = pd.DataFrame(results, columns=columns)

        # Speichern der Ergebnisse
        output_file = f'E:/Datenerhebung MA/MPJPE/Poseformer/Cam1/{person}_{trial}_MPJPE_vector.csv'
        result_df.to_csv(output_file, index=False)
        print(f"Results saved to {output_file}.")
Was wurde geändert:
Flatten von difference_vector:

difference_vector.flatten() wird aufgerufen, um den Vektor von einer Matrix in ein flaches Array zu konvertieren, sodass es als separate Spalten in die Ergebnisliste eingefügt werden kann.
Spaltennamen korrekt angepasst:

Der difference_vector enthält 3 Werte für X, Y und Z, also wird sichergestellt, dass der DataFrame auch die entsprechenden Spalten für Difference Vector X, Difference Vector Y, und Difference Vector Z enthält.
Ergebnislistenerstellung:

Die Anzahl der Marker und die Fehlerwerte stimmen jetzt korrekt mit den Spaltennamen überein.
Zu Beachten:
Der Fehler tritt auf, wenn mehr Daten (in diesem Fall mehr Fehlerwerte) in die results-Liste eingefügt werden, als es Spaltennamen gibt. Der Fix sorgt dafür, dass für jeden Fehlerwert die richtigen Spaltennamen existieren und dass der difference_vector in flacher Form (3D-Komponenten als separate Werte) korrekt angehängt wird.
Nun sollte der Fehler nicht mehr auftreten, und du solltest die CSV-Datei mit der richtigen Anzahl von Spalten und den entsprechenden Werten erhalten.






Du:
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\internals\construction.py:939, in _finalize_columns_and_data(content, columns, dtype)
    938 try:
--> 939     columns = _validate_or_indexify_columns(contents, columns)
    940 except AssertionError as err:
    941     # GH#26429 do not raise user-facing AssertionError

File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\internals\construction.py:986, in _validate_or_indexify_columns(content, columns)
    984 if not is_mi_list and len(columns) != len(content):  # pragma: no cover
    985     # caller's responsibility to check for this...
--> 986     raise AssertionError(
    987         f"{len(columns)} columns passed, passed data had "
    988         f"{len(content)} columns"
    989     )
    990 if is_mi_list:
    991     # check if nested list column, length of each sub-list should be equal

AssertionError: 17 columns passed, passed data had 50 columns

The above exception was the direct cause of the following exception:

ValueError                                Traceback (most recent call last)
Cell In[4], line 92
     90 # Ergebnisse speichern
     91 columns = ['Frame', 'MPJPE (mm)'] + [f'{marker} Error (mm)' for marker in marker_names] + ['Difference Vector X', 'Difference Vector Y', 'Difference Vector Z']
---> 92 result_df = pd.DataFrame(results, columns=columns)
     94 # Speichern der Ergebnisse
     95 output_file = f'E:/Datenerhebung MA/MPJPE/Poseformer/Cam1/{person}_{trial}_MPJPE_vector.csv'

File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\frame.py:806, in DataFrame.__init__(self, data, index, columns, dtype, copy)
    804     if columns is not None:
    805         columns = ensure_index(columns)
--> 806     arrays, columns, index = nested_data_to_arrays(
    807         # error: Argument 3 to "nested_data_to_arrays" has incompatible
    808         # type "Optional[Collection[Any]]"; expected "Optional[Index]"
    809         data,
    810         columns,
    811         index,  # type: ignore[arg-type]
    812         dtype,
    813     )
    814     mgr = arrays_to_mgr(
    815         arrays,
    816         columns,
   (...)
    819         typ=manager,
    820     )
    821 else:

File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\internals\construction.py:520, in nested_data_to_arrays(data, columns, index, dtype)
    517 if is_named_tuple(data[0]) and columns is None:
    518     columns = ensure_index(data[0]._fields)
--> 520 arrays, columns = to_arrays(data, columns, dtype=dtype)
    521 columns = ensure_index(columns)
    523 if index is None:

File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\internals\construction.py:845, in to_arrays(data, columns, dtype)
    842     data = [tuple(x) for x in data]
    843     arr = _list_to_arrays(data)
--> 845 content, columns = _finalize_columns_and_data(arr, columns, dtype)
    846 return content, columns

File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\internals\construction.py:942, in _finalize_columns_and_data(content, columns, dtype)
    939     columns = _validate_or_indexify_columns(contents, columns)
    940 except AssertionError as err:
    941     # GH#26429 do not raise user-facing AssertionError
--> 942     raise ValueError(err) from err
    944 if len(contents) and contents[0].dtype == np.object_:
    945     contents = convert_object_array(contents, dtype=dtype)

ValueError: 17 columns passed, passed data had 50 columns
ChatGPT:
Der Fehler, den du erhältst, tritt auf, weil die Anzahl der Spalten in den results-Daten nicht mit der Anzahl der Spalten in der Liste columns übereinstimmt. In deinem Code gibt es 17 Spalten in der columns-Liste, aber in den results-Daten scheint es 50 Spalten zu geben.

Mögliche Ursachen:
Der difference_vector könnte zu mehr als 3 Werten führen, wenn das Array mehr Dimensionen oder mehr Marker hat, als erwartet.
Der Fehler tritt möglicherweise auf, weil der difference_vector oder die marker_errors nicht in der richtigen Form vorliegen (z. B. als Liste oder Array).
Um diesen Fehler zu beheben, müssen wir sicherstellen, dass:

Die Anzahl der Fehler und Differenzvektoren korrekt in die results-Liste eingefügt wird.
Die columns-Liste mit der tatsächlichen Anzahl der Spalten übereinstimmt.
Lösung:
Stelle sicher, dass der difference_vector für jedes Frame genau 3 Werte für X, Y und Z hat.
Überprüfe, dass die Anzahl der Fehler und Differenzvektoren in jedem Frame mit der Anzahl der Marker und der Differenzvektor-Spalten übereinstimmt.
Hier ist eine aktualisierte Version des Codes, um dieses Problem zu beheben:

Überarbeiteter Code:
python
Kopieren
# Hauptprozess
for person in persons:
    for trial in person_to_trials[person]:
        print(f"Processing {person} - {trial}...")

        # Lade Dateien
        vicon_file, poseformer_file = generate_file_paths(person, trial)
        if not os.path.exists(vicon_file) or not os.path.exists(poseformer_file):
            print(f"File not found: {vicon_file} or {poseformer_file}")
            continue

        vicon_data = pd.read_csv(vicon_file)
        poseformer_data = pd.read_csv(poseformer_file, header=None)
        
        # Entfernen der HIPMIDDLE
        excluded_columns_vicon = [col for col in vicon_data.columns if any(marker in col for marker in ['HIPMIDDLE'])]
        excluded_columns_indices = [vicon_data.columns.get_loc(col) for col in excluded_columns_vicon]
        vicon_data_cleaned = vicon_data.drop(columns=excluded_columns_vicon)
        poseformer_data_cleaned = poseformer_data.drop(columns=poseformer_data.columns[excluded_columns_indices])
        
        # Extrahieren der Marker-Namen
        marker_names = [col.split(':')[0] for col in vicon_data_cleaned.columns if ':X' in col]
        num_frames = min(len(vicon_data_cleaned), len(poseformer_data_cleaned))
 
        results = []
        for i in range(start_frame, min(end_frame + 1, num_frames + 1)):
            vicon_frame = vicon_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            poseformer_frame = poseformer_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            if not (np.isnan(vicon_frame).any() or np.isnan(poseformer_frame).any()):
                try:
                    mpjpe, marker_errors, difference_vector = procrustes_analysis(poseformer_frame, vicon_frame)
                    
                    # Sicherstellen, dass der difference_vector flach ist und nur 3 Werte pro Marker enthält
                    difference_vector_flat = difference_vector.flatten()[:len(marker_names) * 3]  # Auf die Anzahl der Marker x 3 begrenzen
                    
                    # Ergebnisse pro Frame
                    results.append([i, mpjpe] + marker_errors.tolist() + difference_vector_flat.tolist())
                except np.linalg.LinAlgError:
                    # Fehlerfall
                    results.append([i, np.nan] + [np.nan] * len(marker_names) + [np.nan] * 3)  # 3 für den 3D-Vektor
            else:
                # Falls NaN-Werte vorhanden sind
                results.append([i, np.nan] + [np.nan] * len(marker_names) + [np.nan] * 3)  # 3 für den 3D-Vektor

        # Ergebnisse speichern
        columns = ['Frame', 'MPJPE (mm)'] + [f'{marker} Error (mm)' for marker in marker_names] + ['Difference Vector X', 'Difference Vector Y', 'Difference Vector Z']
        result_df = pd.DataFrame(results, columns=columns)

        # Speichern der Ergebnisse
        output_file = f'E:/Datenerhebung MA/MPJPE/Poseformer/Cam1/{person}_{trial}_MPJPE_vector.csv'
        result_df.to_csv(output_file, index=False)
        print(f"Results saved to {output_file}.")
Änderungen im Detail:
Sicherstellen, dass der difference_vector die richtige Anzahl an Werten enthält:

Der difference_vector.flatten() wird auf eine Länge begrenzt, die der Anzahl der Marker multipliziert mit 3 entspricht (weil jeder Marker 3 Werte für X, Y, Z hat). Dies verhindert, dass der difference_vector mehr Werte enthält als erwartet und die Anzahl der Spalten in den results überschreitet.
Spaltenanzahl in der columns-Liste:

Die columns-Liste bleibt unverändert und enthält die richtigen Spaltennamen (Frame, MPJPE, Marker-Fehler und Differenzvektor-Spalten). Dies stellt sicher, dass die DataFrame-Erstellung keine Dimensionierungsprobleme verursacht.
Was könnte weiterhin schief gehen:
Falls du weiterhin mehr als 50 Spalten erhältst, solltest du den Inhalt der results-Liste vor der Erstellung des DataFrames inspizieren, um sicherzustellen, dass die Anzahl der Spalten pro Frame wie erwartet ist. Du kannst dies tun, indem du z.B. den Inhalt von results mit print(len(results)) und print(results[0]) überprüfst.
Ich hoffe, dies behebt den Fehler! Lass mich wissen, ob es noch weitere Probleme gibt.






Du:
für jede frame sieht der difference vector so aus: [[ 0.2958726  -0.06741346  0.45702677]
 [-0.10340105  0.00546262 -0.02319371]
 [ 0.1318474   0.09440713 -0.24253335]
 [ 0.38163163 -0.03150515  0.52146331]
 [-0.14351783 -0.05654866  0.0309752 ]
 [ 0.20624085  0.02954738 -0.13658148]
 [-0.0386109  -0.01774451  0.40966779]
 [-0.23848763  0.26825986 -0.08609678]
 [-0.00677532  0.64868558 -0.5971789 ]
 [-0.10796499 -0.08261035  0.46939426]
 [-0.33022018 -0.39810304 -0.13567427]
 [-0.04661458 -0.39243739 -0.66726884]]
ChatGPT:
Danke für die zusätzliche Information! Es sieht so aus, als ob der difference_vector für jedes Frame ein 2D-Array mit den Dimensionen (n_markers, 3) ist, wobei n_markers die Anzahl der Marker (12 in deinem Beispiel) ist und die 3 die X-, Y- und Z-Komponenten für jeden Marker repräsentiert.

Das bedeutet, dass du den difference_vector für jedes Frame als 12 Zeilen und 3 Spalten erhalten wirst. Wenn du diesen Vektor in dein Ergebnis einfügen möchtest, musst du sicherstellen, dass die Werte korrekt als separate Spalten für Difference Vector X, Difference Vector Y und Difference Vector Z in den DataFrame eingefügt werden.

Lösung:
Anstatt den gesamten difference_vector in ein flaches Array zu konvertieren, das möglicherweise zu einer falschen Anzahl an Spalten führt, solltest du sicherstellen, dass für jeden Marker 3 Spalten für den Unterschied (X, Y, Z) erstellt werden.

Hier ist die angepasste Version deines Codes,






Du:
ich hätte gerne als output ein csv file, dass für jeden marker und für jedes Frame den difference Vektor ausgibt. 
Also jede Zeile ist ein Frame. die erste spalte ist RHIP Difference Vektor X, dann RHIP Difference Vektor y, RHIP Difference Vektor z und das für alle frames
ChatGPT:
Verstanden! Du möchtest also den difference_vector für jeden Marker in separaten Spalten ausgeben, wobei jede Zeile einem Frame entspricht. Die Spalten sollten für jeden Marker und seine X-, Y- und Z-Komponenten des Differenzvektors benannt sein, z. B. RHIP Difference Vektor X, RHIP Difference Vektor Y, RHIP Difference Vektor Z.

Um dies zu erreichen, müssen wir:

Für jeden Frame die Differenzvektoren für jeden Marker extrahieren und sie in die entsprechenden Spalten für X, Y und Z aufteilen.
Die Spalten entsprechend den Markern und ihren X-, Y- und Z-Differenzkomponenten benennen.
Die Ergebnisse für jedes Frame in die CSV-Datei speichern.
Hier ist der angepasste Code, der genau das tut:

Angepasster Code:
python
Kopieren
import pandas as pd
import numpy as np

# Hauptprozess
for person in persons:
    for trial in person_to_trials[person]:
        print(f"Processing {person} - {trial}...")

        # Lade Dateien
        vicon_file, poseformer_file = generate_file_paths(person, trial)
        if not os.path.exists(vicon_file) or not os.path.exists(poseformer_file):
            print(f"File not found: {vicon_file} or {poseformer_file}")
            continue

        vicon_data = pd.read_csv(vicon_file)
        poseformer_data = pd.read_csv(poseformer_file, header=None)
        
        # Entfernen der HIPMIDDLE
        excluded_columns_vicon = [col for col in vicon_data.columns if any(marker in col for marker in ['HIPMIDDLE'])]
        excluded_columns_indices = [vicon_data.columns.get_loc(col) for col in excluded_columns_vicon]
        vicon_data_cleaned = vicon_data.drop(columns=excluded_columns_vicon)
        poseformer_data_cleaned = poseformer_data.drop(columns=poseformer_data.columns[excluded_columns_indices])
        
        # Extrahieren der Marker-Namen
        marker_names = [col.split(':')[0] for col in vicon_data_cleaned.columns if ':X' in col]
        num_frames = min(len(vicon_data_cleaned), len(poseformer_data_cleaned))
 
        results = []
        for i in range(start_frame, min(end_frame + 1, num_frames + 1)):
            vicon_frame = vicon_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            poseformer_frame = poseformer_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            if not (np.isnan(vicon_frame).any() or np.isnan(poseformer_frame).any()):
                try:
                    mpjpe, marker_errors, difference_vector = procrustes_analysis(poseformer_frame, vicon_frame)
                    
                    # Für jeden Marker X, Y, Z Differenzvektor in separate Spalten
                    row = []
                    for j, marker in enumerate(marker_names):
                        # Hole den X, Y, Z Differenzvektor für den Marker
                        row.append(difference_vector[j, 0])  # X
                        row.append(difference_vector[j, 1])  # Y
                        row.append(difference_vector[j, 2])  # Z
                    results.append(row)
                except np.linalg.LinAlgError:
                    # Fehlerfall
                    results.append([np.nan] * len(marker_names) * 3)  # 3 für den 3D-Vektor
            else:
                # Falls NaN-Werte vorhanden sind
                results.append([np.nan] * len(marker_names) * 3)  # 3 für den 3D-Vektor

        # Spaltennamen für das CSV definieren
        columns = []
        for marker in marker_names:
            columns.append(f'{marker} Difference Vector X')
            columns.append(f'{marker} Difference Vector Y')
            columns.append(f'{marker} Difference Vector Z')

        # DataFrame mit den Ergebnissen erstellen
        result_df = pd.DataFrame(results, columns=columns)

        # Ergebnisse speichern
        output_file = f'E:/Datenerhebung MA/MPJPE/Poseformer/Cam1/{person}_{trial}_Difference_Vector.csv'
        result_df.to_csv(output_file, index=False)
        print(f"Results saved to {output_file}.")
Was wurde geändert:
Erstellung der columns-Liste:

Die columns-Liste enthält jetzt für jeden Marker drei Spalten: Marker Name Difference Vector X, Marker Name Difference Vector Y, Marker Name Difference Vector Z. Dadurch wird für jeden Marker der Differenzvektor in den entsprechenden Spalten für jedes Frame gespeichert.
Zeilenstruktur:

Für jedes Frame wird der difference_vector extrahiert und für jeden Marker X-, Y- und Z-Werte in separate Spalten eingefügt.
Jede Zeile in den Ergebnissen entspricht einem Frame, und jede Spalte enthält den Unterschied in X, Y und Z für einen bestimmten Marker.
Speichern der Ergebnisse:

Der result_df DataFrame wird mit den erstellten Spalten und den berechneten Differenzvektoren für jedes Frame erstellt und als CSV-Datei gespeichert.
Beispielhafte CSV-Ausgabe:
Die CSV-Datei wird für jedes Frame folgende Spalten haben:

nginx
Kopieren
RHIP Difference Vector X, RHIP Difference Vector Y, RHIP Difference Vector Z, RANKLE Difference Vector X, RANKLE Difference Vector Y, RANKLE Difference Vector Z, ...
Jede Zeile stellt dann die Differenzvektoren für alle Marker für ein bestimmtes Frame dar.

Hinweise:
Wenn du mehr Marker hast, wird die Anzahl der Spalten entsprechend wachsen, da für jeden Marker drei Spalten (X, Y, Z) erstellt werden.
Der Code geht davon aus, dass du die Anzahl der Marker aus den vicon_data- und poseformer_data-Dateien korrekt extrahierst.
Lass mich wissen, wenn du noch Anpassungen benötigst oder weitere Fragen hast!






Du:
die erste spalte sollte frame sein
ChatGPT:
Klar, wenn die erste Spalte die Frame-Nummer sein soll, müssen wir die results-Liste entsprechend anpassen, damit für jedes Frame die Frame-Nummer in der ersten Spalte und danach die Differenzvektoren für jeden Marker (X, Y, Z) erscheinen.

Hier ist die angepasste Version des Codes, der die Frame-Nummer als erste Spalte in der CSV-Datei hinzufügt:

Angepasster Code:
python
Kopieren
import pandas as pd
import numpy as np

# Hauptprozess
for person in persons:
    for trial in person_to_trials[person]:
        print(f"Processing {person} - {trial}...")

        # Lade Dateien
        vicon_file, poseformer_file = generate_file_paths(person, trial)
        if not os.path.exists(vicon_file) or not os.path.exists(poseformer_file):
            print(f"File not found: {vicon_file} or {poseformer_file}")
            continue

        vicon_data = pd.read_csv(vicon_file)
        poseformer_data = pd.read_csv(poseformer_file, header=None)
        
        # Entfernen der HIPMIDDLE
        excluded_columns_vicon = [col for col in vicon_data.columns if any(marker in col for marker in ['HIPMIDDLE'])]
        excluded_columns_indices = [vicon_data.columns.get_loc(col) for col in excluded_columns_vicon]
        vicon_data_cleaned = vicon_data.drop(columns=excluded_columns_vicon)
        poseformer_data_cleaned = poseformer_data.drop(columns=poseformer_data.columns[excluded_columns_indices])
        
        # Extrahieren der Marker-Namen
        marker_names = [col.split(':')[0] for col in vicon_data_cleaned.columns if ':X' in col]
        num_frames = min(len(vicon_data_cleaned), len(poseformer_data_cleaned))
 
        results = []
        for i in range(start_frame, min(end_frame + 1, num_frames + 1)):
            vicon_frame = vicon_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            poseformer_frame = poseformer_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            if not (np.isnan(vicon_frame).any() or np.isnan(poseformer_frame).any()):
                try:
                    mpjpe, marker_errors, difference_vector = procrustes_analysis(poseformer_frame, vicon_frame)
                    
                    # Zeile für das aktuelle Frame
                    row = [i]  # Frame Nummer hinzufügen
                    for j, marker in enumerate(marker_names):
                        # Hole den X, Y, Z Differenzvektor für den Marker
                        row.append(difference_vector[j, 0])  # X
                        row.append(difference_vector[j, 1])  # Y
                        row.append(difference_vector[j, 2])  # Z
                    results.append(row)
                except np.linalg.LinAlgError:
                    # Fehlerfall
                    results.append([i] + [np.nan] * len(marker_names) * 3)  # 3 für den 3D-Vektor
            else:
                # Falls NaN-Werte vorhanden sind
                results.append([i] + [np.nan] * len(marker_names) * 3)  # 3 für den 3D-Vektor

        # Spaltennamen für das CSV definieren
        columns = ['Frame']  # Erste Spalte ist die Frame-Nummer
        for marker in marker_names:
            columns.append(f'{marker} Difference Vector X')
            columns.append(f'{marker} Difference Vector Y')
            columns.append(f'{marker} Difference Vector Z')

        # DataFrame mit den Ergebnissen erstellen
        result_df = pd.DataFrame(results, columns=columns)

        # Ergebnisse speichern
        output_file = f'E:/Datenerhebung MA/MPJPE/Poseformer/Cam1/{person}_{trial}_Difference_Vector.csv'
        result_df.to_csv(output_file, index=False)
        print(f"Results saved to {output_file}.")
Was wurde geändert:
Frame als erste Spalte:
Die erste Spalte der results-Liste enthält nun die Frame-Nummer (row = [i]), bevor die Differenzvektoren für die Marker angehängt werden.
columns-Liste für DataFrame:
Die columns-Liste enthält jetzt ['Frame'] als erste Spalte und danach für jeden Marker die Differenzvektoren in den Spalten X, Y, und Z.
Beispielhafte CSV-Ausgabe:
Die resultierende CSV-Datei hat für jedes Frame folgende Struktur:

mathematica
Kopieren
Frame, RHIP Difference Vector X, RHIP Difference Vector Y, RHIP Difference Vector Z, RANKLE Difference Vector X, RANKLE Difference Vector Y, RANKLE Difference Vector Z, ...
Jede Zeile stellt die Differenzvektoren für alle Marker für ein bestimmtes Frame dar, wobei die erste Spalte die Frame-Nummer enthält.

Hinweise:
Wenn du weitere Marker hinzufügst, werden mehr Spalten für jeden Marker und seine X-, Y- und Z-Differenzwerte erstellt.
Dieser Code speichert die Datei unter dem Pfad, den du in der Variablen output_file angibst.
Lass mich wissen, ob das nun deinen Anforderungen entspricht oder ob noch Anpassungen erforderlich sind!






Du:
AEN262 01 Squat Cam1 Difference Vector

Visualisierung konnte nicht angezeigt werden
ich habe nun dieses file 
ChatGPT:
Du hast eine Datei mit dem Namen AEN262_01_squat_Cam1_Difference_Vector.csv hochgeladen. Möchtest du, dass ich die Datei analysiere oder bei etwas Bestimmtem damit helfe? Lass mich wissen, was du tun möchtest!






Du:
gerne würde ich den durchschnittlichen difference vector für jedes Gelenk berechnen
ChatGPT:
Die Datei enthält Differenzvektoren für verschiedene Gelenke, und jede Zeile repräsentiert ein Frame. Um den durchschnittlichen Differenzvektor für jedes Gelenk zu berechnen, werden wir für jedes Gelenk (z. B. RHIP, RKNE, RANK, etc.) die Mittelwerte der X-, Y- und Z-Differenzwerte berechnen.

Ich werde den Durchschnitt für jedes Gelenk (für X, Y, und Z) berechnen und dir die Ergebnisse als DataFrame anzeigen.

Berechnung des durchschnittlichen Differenzvektors:
Ich werde die Mittelwerte für jedes Gelenk und jeden Vektor (X, Y, Z) berechnen. Jetzt führe ich die Berechnung aus. ​​

Hier sind die durchschnittlichen Differenzvektoren für jedes Gelenk (dargestellt durch die Mittelwerte der X-, Y- und Z-Komponenten) über alle Frames:

RHIP:

X: -0.091257
Y: 0.003593
Z: 0.047408
RKNE:

X: 0.006931
Y: -0.016428
Z: -0.073518
RANK:

X: 0.084861
Y: -0.056018
Z: -0.090405
LHIP:

X: -0.019676
Y: 0.096286
Z: 0.128571
LKNE:

X: 0.026684
Y: 0.015218
Z: 0.031942
LANK:

X: 0.043226
Y: -0.068554
Z: 0.087098
LSHO:

X: 0.048781
Y: 0.005133
Z: -0.012155
LELB:

X: -0.017222
Y: -0.055556
Z: 0.021187
LWRIST:

X: -0.036993
Y: 0.109879
Z: -0.006884
RSHO:

X: -0.013342
Y: -0.003462
Z: -0.030634
RELB:

X: -0.023448
Y: -0.055496
Z: -0.019501
RWRIST:

X: -0.008546
Y: 0.025405
Z: -0.083109
Diese Werte stellen die durchschnittlichen Differenzvektoren für jedes Gelenk dar und spiegeln die durchschnittliche Verschiebung in den X-, Y- und Z-Richtungen wider.

Möchtest du diese Ergebnisse in einer CSV-Datei speichern oder weiter mit diesen Daten arbeiten? ​​






Du:
multipliziere jede zahl mit 528.9535022863101
ChatGPT:
Hier sind die skalierten Werte der durchschnittlichen Differenzvektoren, die mit dem Faktor 528.9535022863101 multipliziert wurden:

RHIP:

X: -48.270694
Y: 1.900388
Z: 25.076542
RKNE:

X: 3.666179
Y: -8.689796
Z: -38.887864
RANK:

X: 44.887637
Y: -29.630683
Z: -47.819919
LHIP:

X: -10.407744
Y: 50.930892
Z: 68.008105
LKNE:

X: 14.114669
Y: 8.049448
Z: 16.895684
LANK:

X: 22.864541
Y: -36.261732
Z: 46.071023
LSHO:

X: 25.802898
Y: 2.714939
Z: -6.429345
LELB:

X: -9.109393
Y: -29.386789
Z: 11.206912
LWRIST:

X: -19.567540
Y: 58.121098
Z: -3.641499
RSHO:

X: -7.057521
Y: -1.830987
Z: -16.203826
RELB:

X: -12.402652
Y: -29.354583
Z: -10.315019
RWRIST:

X: -4.520380
Y: 13.437805
Z: -43.960793
Möchtest du diese skalierten Werte in einer CSV-Datei speichern? ​​






Du:
AEN262 02 Squat Cam1 Difference Vector

Visualisierung konnte nicht angezeigt werden
nun mach bitte das genau gleiche für diese daten
ChatGPT:
Die neue Datei hat eine ähnliche Struktur wie die vorherige, mit Differenzvektoren für jedes Gelenk und für jedes Frame. Ich werde nun die durchschnittlichen Differenzvektoren für jedes Gelenk berechnen und diese mit dem gleichen Faktor (528.9535022863101) multiplizieren.

Ich werde diesen Vorgang jetzt durchführen. ​​

Hier sind die skalierten Werte der durchschnittlichen Differenzvektoren für die neue Datei, multipliziert mit dem Faktor 528.9535022863101:

RHIP:

X: -53.672447
Y: 6.705113
Z: 27.400231
RKNE:

X: 4.819720
Y: -4.660000
Z: -37.178917
RANK:

X: 56.401145
Y: -32.121899
Z: -52.183567
LHIP:

X: -22.173249
Y: 55.916423
Z: 73.921121
LKNE:

X: 9.879307
Y: 11.627960
Z: 20.537616
LANK:

X: 24.833543
Y: -39.740032
Z: 43.498682
LSHO:

X: 14.292567
Y: 4.660486
Z: -5.848290
LELB:

X: -10.779292
Y: -25.123969
Z: 14.510559
LWRIST:

X: -18.748890
Y: 38.994042
Z: -7.549201
RSHO:

X: -10.145925
Y: -4.477426
Z: -14.377169
RELB:

X: -2.317222
Y: -29.000998
Z: -12.651049
RWRIST:

X: 7.610743
Y: 17.220301
Z: -50.080018
Möchtest du diese skalierten Werte auch in einer CSV-Datei speichern oder weiter damit arbeiten? ​​






Du:
ich habe ein ordner mit vielen solchen Dateien. Nun möchte ich für alle jeweils den mittelwert aller Vektoren (so wie du gerade geamacht hast) berechnen und alle zusammen in einem file zusammenfassen, wobei die Zeile der Filename ist und dann die durchschnittsvektoren 
ChatGPT:
Klar, das lässt sich umsetzen! Der Prozess besteht darin:

Alle Dateien im angegebenen Ordner zu laden.
Für jede Datei den durchschnittlichen Differenzvektor berechnen (wie wir es für die einzelnen Dateien gemacht haben).
Diese Werte in einem DataFrame zu sammeln, wobei der Dateiname als Zeile und die durchschnittlichen Vektoren als Spalten dienen.
Schließlich die Ergebnisse in einer CSV-Datei zu speichern.
Ich werde dir den Code zur Verfügung stellen, der diese Schritte ausführt. Wenn du mir den Pfad zu dem Ordner gibst, kann ich ihn für dich ausführen. Alternativ kannst du den Ordnerpfad direkt angeben.






Du:
E:\Datenerhebung MA\MPJPE\difference_vector\Poseformer
ChatGPT:
Da ich aktuell nicht direkt auf dein Dateisystem zugreifen kann, benötige ich, dass du die Dateien hochlädst oder mir den Ordnerinhalt zur Verfügung stellst.

Falls du die Dateien manuell hochladen möchtest, kannst du mir mehrere Dateien gleichzeitig zur Verfügung stellen. Alternativ, wenn du den Code selbst ausführen möchtest, gebe ich dir den entsprechenden Python-Code, den du lokal ausführen kannst.

Code zur Berechnung der durchschnittlichen Vektoren für alle Dateien und zum Speichern der Ergebnisse:
python
Kopieren
import os
import pandas as pd
import numpy as np

# Ordnerpfad mit den CSV-Dateien
folder_path = r'E:\Datenerhebung MA\MPJPE\difference_vector\Poseformer'

# Liste der CSV-Dateien im Ordner
files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]

# Liste zum Speichern der Ergebnisse
all_results = []

# Skalierungsfaktor
scaling_factor = 528.9535022863101

# Iteration über alle Dateien
for file in files:
    file_path = os.path.join(folder_path, file)
    
    # Lade die Datei
    data = pd.read_csv(file_path)
    
    # Berechnung der durchschnittlichen Differenzvektoren
    difference_columns = [col for col in data.columns if 'Difference Vector' in col]
    average_difference_vectors = data[difference_columns].mean()
    
    # Skalierung der Differenzvektoren
    scaled_average_difference_vectors = average_difference_vectors * scaling_factor
    
    # Füge den Dateinamen als Zeile hinzu
    result_row = [file] + scaled_average_difference_vectors.tolist()
    all_results.append(result_row)

# Spaltennamen
columns = ['Filename'] + [col.split(' ')[0] + ' Difference Vector X' for col in difference_columns]

# Ergebnisse in DataFrame umwandeln
result_df = pd.DataFrame(all_results, columns=columns)

# Speichern der Ergebnisse in einer CSV-Datei
output_file = r'E:\Datenerhebung MA\MPJPE\difference_vector\Poseformer\average_difference_vectors.csv'
result_df.to_csv(output_file, index=False)

print(f"Results saved to {output_file}.")
Was der Code tut:
Lesen der CSV-Dateien: Alle CSV-Dateien im angegebenen Ordner werden geladen.
Berechnung der Durchschnittswerte: Für jede Datei werden die Durchschnittswerte der Differenzvektoren berechnet und skaliert.
Ergebnisse speichern: Alle Ergebnisse werden in einer CSV-Datei namens average_difference_vectors.csv gespeichert. Jede Zeile enthält den Dateinamen und die berechneten Vektoren.
Falls du diesen Code selbst ausführen möchtest, stelle sicher, dass du den Pfad zu deinem Ordner korrekt angibst und den Code in deiner Python-Umgebung ausführst.

Lass mich wissen, wenn du weitere Hilfe benötigst!






Du:
import numpy as np
import pandas as pd
import os

# Parameter
cam = ("1")
persons = ["AEN262", "DMN261", "JKN261", "MAN262", "MUN261", "NSN261"] #"AEN262", "DMN261", "JKN261", "MAN262", "MUN261", "NSN261"
trials_v1 = [ '01_step', '02_step', '05_squat', '06_squat', '09_ebs', '10_ebs','13_tubes', '14_tubes', '17_sprint', '18_sprint', '21_torso', '22_torso'] #'01_step', '02_step', '05_squat', '06_squat', '09_ebs', '10_ebs', '13_tubes', '14_tubes', '17_sprint', '18_sprint', '21_torso', '22_torso'
trials_v2 = ['01_squat', '02_squat', '05_torso', '06_torso', '09_ebs', '10_ebs', '13_step', '14_step', '17_tubes', '18_tubes', '21_sprint', '22_sprint'] #'01_squat', '02_squat', '05_torso', '06_torso', '09_ebs', '10_ebs', '13_step', '14_step', '17_tubes', '18_tubes', '21_sprint', '22_sprint'

person_to_trials = {
    "AEN262": trials_v2,
    "DMN261": trials_v2, 
    "MAN262": trials_v1,
    "MUN261": trials_v1,
    "NSN261": trials_v2,
    "JKN261": trials_v1,
}

start_frame = 500
end_frame = 2000

# Funktion: Dateipfade erstellen
def generate_file_paths(person, trial):
    vicon_path = f'E:/Datenerhebung MA/Vicon_csv/mittelwert/{person}/60fps/{trial}_mittelwert_60fps.csv'
    poseformer_path = f'E:/Datenerhebung MA/PoseFormerV2 Daten/{person}/Cam{cam}/{trial}_{cam}/pose3D_keypoints/combined/combined_keypoints.csv'
    return vicon_path, poseformer_path

# Funktion: Procrustes-Analyse
def procrustes_analysis(A, B):
    A_centroid, B_centroid = np.mean(A, axis=0), np.mean(B, axis=0)
    A_centered, B_centered = A - A_centroid, B - B_centroid
    A_scale = np.sqrt(np.sum(A_centered**2) / A_centered.shape[0])
    B_scale = np.sqrt(np.sum(B_centered**2) / B_centered.shape[0])
    A_normalized, B_normalized = A_centered / A_scale, B_centered / B_scale

    H = B_normalized.T @ A_normalized
    U, _, Vt = np.linalg.svd(H)
    R = Vt.T @ U.T
    A_transformed = A_normalized @ R

    
    
    difference_vector = A_transformed - B_normalized
    marker_errors_in_mm = np.linalg.norm((A_transformed - B_normalized), axis=1) * B_scale
    mpjpe_in_mm = np.mean(marker_errors_in_mm)
    return mpjpe_in_mm, marker_errors_in_mm, difference_vector



# Hauptprozess
for person in persons:
    for trial in person_to_trials[person]:
        print(f"Processing {person} - {trial}...")

        # Lade Dateien
        vicon_file, poseformer_file = generate_file_paths(person, trial)
        if not os.path.exists(vicon_file) or not os.path.exists(poseformer_file):
            print(f"File not found: {vicon_file} or {poseformer_file}")
            continue

        vicon_data = pd.read_csv(vicon_file)
        poseformer_data = pd.read_csv(poseformer_file, header=None)
        
        # Entfernen der HIPMIDDLE
        excluded_columns_vicon = [col for col in vicon_data.columns if any(marker in col for marker in ['HIPMIDDLE'])]
        excluded_columns_indices = [vicon_data.columns.get_loc(col) for col in excluded_columns_vicon]
        vicon_data_cleaned = vicon_data.drop(columns=excluded_columns_vicon)
        poseformer_data_cleaned = poseformer_data.drop(columns=poseformer_data.columns[excluded_columns_indices])
        
        # Extrahieren der Marker-Namen
        marker_names = [col.split(':')[0] for col in vicon_data_cleaned.columns if ':X' in col]
        num_frames = min(len(vicon_data_cleaned), len(poseformer_data_cleaned))
 
        results = []
        for i in range(start_frame, min(end_frame + 1, num_frames + 1)):
            vicon_frame = vicon_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            poseformer_frame = poseformer_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            if not (np.isnan(vicon_frame).any() or np.isnan(poseformer_frame).any()):
                try:
                    mpjpe, marker_errors, difference_vector = procrustes_analysis(poseformer_frame, vicon_frame)
                  
                    # Zeile für das aktuelle Frame
                    row = [i]  # Frame Nummer hinzufügen
                    for j, marker in enumerate(marker_names):
                        # Hole den X, Y, Z Differenzvektor für den Marker
                        row.append(difference_vector[j, 0])  # X
                        row.append(difference_vector[j, 1])  # Y
                        row.append(difference_vector[j, 2])  # Z
                    results.append(row)
                except np.linalg.LinAlgError:
                    # Fehlerfall
                    results.append([i] + [np.nan] * len(marker_names) * 3)  # 3 für den 3D-Vektor
            else:
                # Falls NaN-Werte vorhanden sind
                results.append([i] + [np.nan] * len(marker_names) * 3)  # 3 für den 3D-Vektor

        # Spaltennamen für das CSV definieren
        columns = ['Frame']  # Erste Spalte ist die Frame-Nummer
        for marker in marker_names:
            columns.append(f'{marker} Difference Vector X')
            columns.append(f'{marker} Difference Vector Y')
            columns.append(f'{marker} Difference Vector Z')

        # DataFrame mit den Ergebnissen erstellen
        result_df = pd.DataFrame(results, columns=columns)

        # Ergebnisse speichern
        output_file = f'E:/Datenerhebung MA/MPJPE/difference_vector/Poseformer/{person}_{trial}_Cam{cam}_Difference_Vector.csv'
        result_df.to_csv(output_file, index=False)
        print(f"Results saved to {output_file}.")


ich habe diesen code.
gerne möchte ich noch, dass der B_scale für jedes Frame in einer letzten spalte ins csv gespeichert wird
ChatGPT:
Um den B_scale für jedes Frame in einer letzten Spalte zu speichern, müssen wir den Wert von B_scale für jedes Frame berechnen und ihn zu der Liste der Ergebnisse (results) hinzufügen, bevor wir die CSV-Datei speichern. Wir fügen dann eine zusätzliche Spalte für B_scale zu den Spaltennamen (columns) hinzu.

Ich werde den Code entsprechend anpassen:

Anpassungen:
Berechnung von B_scale in jedem Frame und Hinzufügen zur Ergebniszeile (row).
Hinzufügen einer neuen Spalte in columns für B_scale.
Hier ist der angepasste Code:

python
Kopieren
# Hauptprozess
for person in persons:
    for trial in person_to_trials[person]:
        print(f"Processing {person} - {trial}...")

        # Lade Dateien
        vicon_file, poseformer_file = generate_file_paths(person, trial)
        if not os.path.exists(vicon_file) or not os.path.exists(poseformer_file):
            print(f"File not found: {vicon_file} or {poseformer_file}")
            continue

        vicon_data = pd.read_csv(vicon_file)
        poseformer_data = pd.read_csv(poseformer_file, header=None)
        
        # Entfernen der HIPMIDDLE
        excluded_columns_vicon = [col for col in vicon_data.columns if any(marker in col for marker in ['HIPMIDDLE'])]
        excluded_columns_indices = [vicon_data.columns.get_loc(col) for col in excluded_columns_vicon]
        vicon_data_cleaned = vicon_data.drop(columns=excluded_columns_vicon)
        poseformer_data_cleaned = poseformer_data.drop(columns=poseformer_data.columns[excluded_columns_indices])
        
        # Extrahieren der Marker-Namen
        marker_names = [col.split(':')[0] for col in vicon_data_cleaned.columns if ':X' in col]
        num_frames = min(len(vicon_data_cleaned), len(poseformer_data_cleaned))
 
        results = []
        for i in range(start_frame, min(end_frame + 1, num_frames + 1)):
            vicon_frame = vicon_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            poseformer_frame = poseformer_data_cleaned.iloc[i - 1, 1:].values.reshape(-1, 3)
            if not (np.isnan(vicon_frame).any() or np.isnan(poseformer_frame).any()):
                try:
                    mpjpe, marker_errors, difference_vector = procrustes_analysis(poseformer_frame, vicon_frame)
                  
                    # Berechnung des B_scale für das aktuelle Frame
                    B_scale = np.sqrt(np.sum((vicon_frame - np.mean(vicon_frame, axis=0))**2) / vicon_frame.shape[0])

                    # Zeile für das aktuelle Frame
                    row = [i]  # Frame Nummer hinzufügen
                    for j, marker in enumerate(marker_names):
                        # Hole den X, Y, Z Differenzvektor für den Marker
                        row.append(difference_vector[j, 0])  # X
                        row.append(difference_vector[j, 1])  # Y
                        row.append(difference_vector[j, 2])  # Z
                    
                    # Füge den B_scale-Wert für das aktuelle Frame hinzu
                    row.append(B_scale)
                    results.append(row)
                except np.linalg.LinAlgError:
                    # Fehlerfall
                    results.append([i] + [np.nan] * len(marker_names) * 3 + [np.nan])  # 3 für den 3D-Vektor und B_scale
            else:
                # Falls NaN-Werte vorhanden sind
                results.append([i] + [np.nan] * len(marker_names) * 3 + [np.nan])  # 3 für den 3D-Vektor und B_scale

        # Spaltennamen für das CSV definieren
        columns = ['Frame']  # Erste Spalte ist die Frame-Nummer
        for marker in marker_names:
            columns.append(f'{marker} Difference Vector X')
            columns.append(f'{marker} Difference Vector Y')
            columns.append(f'{marker} Difference Vector Z')
        
        # Füge die B_scale-Spalte hinzu
        columns.append('B_scale')

        # DataFrame mit den Ergebnissen erstellen
        result_df = pd.DataFrame(results, columns=columns)

        # Ergebnisse speichern
        output_file = f'E:/Datenerhebung MA/MPJPE/difference_vector/Poseformer/{person}_{trial}_Cam{cam}_Difference_Vector.csv'
        result_df.to_csv(output_file, index=False)
        print(f"Results saved to {output_file}.")
Änderungen im Code:
Berechnung von B_scale:

B_scale wird nun für jedes Frame berechnet und als letzte Zahl in der Zeile (row) hinzugefügt.
Es wird basierend auf den vicon_frame-Daten berechnet, indem der Abstand der Punkte vom Schwerpunkt normalisiert wird.
Erweiterung der columns-Liste:

Eine neue Spalte B_scale wurde am Ende der columns-Liste hinzugefügt.
Ergebnisse speichern:

Der B_scale-Wert wird jetzt für jedes Frame in die CSV-Datei geschrieben.
Ergebnis:
Die CSV-Datei enthält jetzt eine zusätzliche Spalte namens B_scale, die den Skalierungsfaktor für jedes Frame darstellt.

Möchtest du diesen Code verwenden oder hast du weitere Fragen dazu?






Du:
AEN262 01 Squat Cam1 Difference Vector

Visualisierung konnte nicht angezeigt werden
ich habe nun dieses file
ChatGPT:
Du hast eine neue Datei hochgeladen mit dem Namen AEN262_01_squat_Cam1_Difference_Vector.csv. Möchtest du, dass ich die Datei analysiere oder eine bestimmte Berechnung für diese Datei durchführe? Lass mich wissen, wie ich dir helfen kann!






Du:
ich möchte jeweils den durchschnittlichen Vektor der einzelnen Marker berechnen. Davor möchte ich den Vektor aber immernoch mit dem B_scale Faktor multiplizieren. 
ChatGPT:
Klar, ich verstehe! Du möchtest den durchschnittlichen Differenzvektor für jeden Marker berechnen und vorher den Vektor mit dem B_scale-Faktor multiplizieren.

Hier sind die Schritte, die wir ausführen müssen:

Den B_scale-Faktor berechnen für jedes Frame.
Den Differenzvektor jedes Markers mit dem B_scale-Faktor multiplizieren.
Den durchschnittlichen Vektor für jeden Marker berechnen.
Ich werde den Code anpassen, um diesen Vorgang durchzuführen und dir die gewünschten Ergebnisse zu liefern. Ich werde den Code auf die hochgeladene Datei anwenden. Lass mich das gleich erledigen.


Analyse angehalten





Du:
der B_scale factor ist immer in der letzten spalte
ChatGPT:
Ah, verstehe! Der B_scale-Faktor ist in der letzten Spalte gespeichert. In diesem Fall müssen wir sicherstellen, dass wir diesen Wert für jedes Frame korrekt extrahieren und dann den Differenzvektor jedes Markers mit diesem B_scale-Faktor multiplizieren.

Ich werde den Code entsprechend anpassen, um den B_scale-Wert aus der letzten Spalte zu extrahieren und den Vektor mit diesem Faktor zu multiplizieren, bevor wir den durchschnittlichen Vektor für jedes Gelenk berechnen.

Lass mich das für dich durchführen.


Analyse angehalten
